{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70220fa",
   "metadata": {},
   "source": [
    "## Example notebook demonstrating PyTorch & Optuna on Dask\n",
    "\n",
    "A derived PyTorch example of a Generative Adversarial Network (GAN) being optimized with Optuna and traied on Dask.\n",
    "\n",
    "Note: To focus on GPU load and demontration purposes, this notebook generates fake data in-memory. Likely to be easily swapped out with your intended dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44900f9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n"
     ]
    }
   ],
   "source": [
    "# Derived partially from\n",
    "# - https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "import os\n",
    "\n",
    "import coiled\n",
    "\n",
    "import optuna\n",
    "from optuna.integration.dask import DaskStorage\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from distributed import wait\n",
    "\n",
    "print(f\"Cuda is available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Root directory for dataset\n",
    "dataroot = \"data/celeba\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 0  # IMPORTANT w/ optuna; it launches a daemonic process, so PyTorch can't itself use it then.\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "\n",
    "# We create a fake image dataset. This ought to be replaced by\n",
    "# your actual dataset or pytorch's example datasets. We do this here\n",
    "# to focus more on computation than actual convergence.\n",
    "class FakeImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, count=1_000):\n",
    "        self.labels = np.random.randint(0, 5, size=count)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        torch.random.seed = label\n",
    "        img = torch.rand(3, image_size, image_size)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "        \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu, activation=None):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            activation or nn.Sigmoid()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "    @classmethod\n",
    "    def from_trial(cls, trial):\n",
    "        activations = [nn.Sigmoid]\n",
    "        idx = trial.suggest_categorical(\"generator_activation\", list(range(len(activations))))\n",
    "        activation = activations[idx]()\n",
    "        return cls(ngpu, activation)\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu, leaky_relu_slope=0.2, activation=None):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is ``(nc) x 64 x 64``\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(leaky_relu_slope, inplace=True),\n",
    "            # state size. ``(ndf) x 32 x 32``\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(leaky_relu_slope, inplace=True),\n",
    "            # state size. ``(ndf*2) x 16 x 16``\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(leaky_relu_slope, inplace=True),\n",
    "            # state size. ``(ndf*4) x 8 x 8``\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(leaky_relu_slope, inplace=True),\n",
    "            # state size. ``(ndf*8) x 4 x 4``\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            activation or nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_trial(cls, trial):\n",
    "        activations = [nn.Sigmoid]\n",
    "        idx = trial.suggest_categorical(\"descriminator_activation\", list(range(len(activations))))\n",
    "        activation = activations[idx]()\n",
    "        \n",
    "        slopes = np.arange(0.1, 0.4, 0.1)\n",
    "        idx = trial.suggest_categorical(\"descriminator_leaky_relu_slope\", list(range(len(slopes))))\n",
    "        leaky_relu_slope = slopes[idx]\n",
    "        return cls(ngpu, leaky_relu_slope, activation)\n",
    "        \n",
    "\n",
    "def objective(trial):\n",
    "    dataset = FakeImageDataset()\n",
    "\n",
    "    # Create the dataloader\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=workers)\n",
    "    \n",
    "    # Decide which device we want to run on\n",
    "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "\n",
    "    ############################\n",
    "    ### Create the generator ###\n",
    "    netG = Generator.from_trial(trial).to(device)\n",
    "\n",
    "    # Handle multi-GPU if desired\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "    # Apply the ``weights_init`` function to randomly initialize all weights\n",
    "    #  to ``mean=0``, ``stdev=0.02``.\n",
    "    netG.apply(weights_init)\n",
    "\n",
    "    ################################\n",
    "    ### Create the Discriminator ###\n",
    "    netD = Discriminator.from_trial(trial).to(device)\n",
    "\n",
    "    # Handle multi-GPU if desired\n",
    "    if (device.type == 'cuda') and (ngpu > 1):\n",
    "        netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "    # Apply the ``weights_init`` function to randomly initialize all weights\n",
    "    # like this: ``to mean=0, stdev=0.2``.\n",
    "    netD.apply(weights_init)\n",
    "\n",
    "    ############################################\n",
    "    ### Remaining crierion, optimizers, etc. ###\n",
    "    # Initialize the ``BCELoss`` function\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Create batch of latent vectors that we will use to visualize\n",
    "    #  the progression of the generator\n",
    "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "    # Establish convention for real and fake labels during training\n",
    "    real_label = 1.\n",
    "    fake_label = 0.\n",
    "    \n",
    "    # Learning rate for optimizers\n",
    "    lr = 0.00001\n",
    "\n",
    "    # Setup Adam optimizers for both G and D\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    \n",
    "    #####################\n",
    "    ### Training Loop ###\n",
    "\n",
    "    # Lists to keep track of progress\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    iters = 0\n",
    "\n",
    "    print(\"Starting Training Loop...\")\n",
    "    # For each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        # For each batch in the dataloader\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "            ############################\n",
    "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            ###########################\n",
    "            ## Train with all-real batch\n",
    "            netD.zero_grad()\n",
    "            # Format batch\n",
    "            real_cpu = data[0].to(device)\n",
    "            b_size = real_cpu.size(0)\n",
    "            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "            # Forward pass real batch through D\n",
    "            output = netD(real_cpu).view(-1)\n",
    "            # Calculate loss on all-real batch\n",
    "            errD_real = criterion(output, label)\n",
    "            # Calculate gradients for D in backward pass\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            ## Train with all-fake batch\n",
    "            # Generate batch of latent vectors\n",
    "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "            # Generate fake image batch with G\n",
    "            fake = netG(noise)\n",
    "            label.fill_(fake_label)\n",
    "            # Classify all fake batch with D\n",
    "            output = netD(fake.detach()).view(-1)\n",
    "            # Calculate D's loss on the all-fake batch\n",
    "            errD_fake = criterion(output, label)\n",
    "            # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "            # Compute error of D as sum over the fake and the real batches\n",
    "            errD = errD_real + errD_fake\n",
    "            # Update D\n",
    "            optimizerD.step()\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network: maximize log(D(G(z)))\n",
    "            ###########################\n",
    "            netG.zero_grad()\n",
    "            label.fill_(real_label)  # fake labels are real for generator cost\n",
    "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "            output = netD(fake).view(-1)\n",
    "            # Calculate G's loss based on this output\n",
    "            errG = criterion(output, label)\n",
    "            # Calculate gradients for G\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            # Update G\n",
    "            optimizerG.step()\n",
    "\n",
    "            # Output training stats\n",
    "            if i % 50 == 0:\n",
    "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                      % (epoch, num_epochs, i, len(dataloader),\n",
    "                         errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "            # Save Losses for plotting later\n",
    "            G_losses.append(errG.item())\n",
    "            D_losses.append(errD.item())\n",
    "\n",
    "            # Check how the generator is doing by saving G's output on fixed_noise\n",
    "            if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "                with torch.no_grad():\n",
    "                    fake = netG(fixed_noise).detach().cpu()\n",
    "                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "            iters += 1\n",
    "\n",
    "        # Report to Optuna\n",
    "        trial.report(errD.item(), epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return errD.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f3952",
   "metadata": {},
   "source": [
    "### Start Coiled cluster using software package w/ GPU workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "572f5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the software environment and cluster name\n",
    "name = \"pytorch-optuna-example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75516f5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating software environment...\n",
      "--- Logs from remote build follow ---\n",
      "[2023-04-17 09:15:05,031][INFO    ][cloud-env.build] Downloading environment definition\n",
      "[2023-04-17 09:15:05,105][INFO    ][cloud-env.build] Installing environment.yaml: \n",
      "channels:\n",
      "  - pytorch\n",
      "  - nvidia\n",
      "  - conda-forge\n",
      "  - defaults\n",
      "dependencies:\n",
      "  - dask=2023.2\n",
      "  - pytorch=2.0.0\n",
      "  - pytorch-cuda=11.8\n",
      "  - optuna=3.1.0\n",
      "  - torchvision\n",
      "  - cudatoolkit=11.8.0\n",
      "  - pynvml=11.4.1\n",
      "  - numpy\n",
      "[2023-04-17 09:15:05,105][INFO    ][cloud-env.subproc] micromamba create -f /tmp/tmp8itj5hi8.yml -r /opt/coiled/rt -p /opt/coiled/env -y --no-pyc --json\n",
      "[2023-04-17 09:18:24,100][INFO    ][cloud-env.subproc] micromamba -r /opt/coiled/rt clean -a\n",
      "                                           __\n",
      "          __  ______ ___  ____ _____ ___  / /_  ____ _\n",
      "         / / / / __ `__ \\/ __ `/ __ `__ \\/ __ \\/ __ `/\n",
      "        / /_/ / / / / / / /_/ / / / / / / /_/ / /_/ /\n",
      "       / .___/_/ /_/ /_/\\__,_/_/ /_/ /_/_.___/\\__,_/\n",
      "      /_/\n",
      "Collect information..\n",
      "Cleaning index cache..\n",
      "Cleaning lock files..\n",
      "  Package file                                           Size\n",
      "───────────────────────────────────────────────────────────────\n",
      "  /opt/coiled/rt/pkgs\n",
      "───────────────────────────────────────────────────────────────\n",
      "  _libgcc_mutex-0.1-conda_forge.tar.bz2                   3kB\n",
      "  _openmp_mutex-4.5-2_gnu.tar.bz2                        24kB\n",
      "  alembic-1.10.3-pyhd8ed1ab_0.conda                     148kB\n",
      "  blas-1.0-mkl.tar.bz2                                    1kB\n",
      "  bokeh-2.4.3-pyhd8ed1ab_3.tar.bz2                       14MB\n",
      "  brotlipy-0.7.0-py310h5764c6d_1005.tar.bz2             351kB\n",
      "  bzip2-1.0.8-h7f98852_4.tar.bz2                        496kB\n",
      "  ca-certificates-2022.12.7-ha878542_0.conda            146kB\n",
      "  certifi-2022.12.7-pyhd8ed1ab_0.conda                  151kB\n",
      "  cffi-1.15.1-py310h255011f_3.conda                     237kB\n",
      "  charset-normalizer-3.1.0-pyhd8ed1ab_0.conda            45kB\n",
      "  click-8.1.3-unix_pyhd8ed1ab_2.tar.bz2                  76kB\n",
      "  cloudpickle-2.2.1-pyhd8ed1ab_0.conda                   28kB\n",
      "  cmaes-0.9.1-pyhd8ed1ab_0.conda                         21kB\n",
      "  colorama-0.4.6-pyhd8ed1ab_0.tar.bz2                    25kB\n",
      "  colorlog-6.7.0-py310hff52083_1.tar.bz2                 18kB\n",
      "  cryptography-40.0.2-py310h34c0648_0.conda               2MB\n",
      "  cuda-cudart-11.8.89-0.tar.bz2                         202kB\n",
      "  cuda-cupti-11.8.87-0.tar.bz2                           27MB\n",
      "  cuda-libraries-11.8.0-0.tar.bz2                         2kB\n",
      "  cuda-nvrtc-11.8.89-0.tar.bz2                           20MB\n",
      "  cuda-nvtx-11.8.86-0.tar.bz2                            58kB\n",
      "  cuda-runtime-11.8.0-0.tar.bz2                           1kB\n",
      "  cudatoolkit-11.8.0-h37601d7_11.conda                  667MB\n",
      "  cytoolz-0.12.0-py310h5764c6d_1.tar.bz2                398kB\n",
      "  dask-2023.2.1-pyhd8ed1ab_0.conda                        7kB\n",
      "  dask-core-2023.2.1-pyhd8ed1ab_0.conda                 836kB\n",
      "  distributed-2023.2.1-pyhd8ed1ab_0.conda               749kB\n",
      "  ffmpeg-4.3-hf484d3e_0.tar.bz2                          10MB\n",
      "  filelock-3.11.0-pyhd8ed1ab_0.conda                     14kB\n",
      "  freetype-2.12.1-hca18f0e_1.conda                      626kB\n",
      "  fsspec-2023.4.0-pyh1a96a4e_0.conda                    111kB\n",
      "  gmp-6.2.1-h58526e2_0.tar.bz2                          826kB\n",
      "  gmpy2-2.1.2-py310h3ec546c_1.tar.bz2                   220kB\n",
      "  gnutls-3.6.13-h85f3911_1.tar.bz2                        2MB\n",
      "  greenlet-2.0.2-py310heca2aa9_0.conda                  192kB\n",
      "  heapdict-1.0.1-py_0.tar.bz2                             7kB\n",
      "  idna-3.4-pyhd8ed1ab_0.tar.bz2                          57kB\n",
      "  importlib-metadata-6.4.1-pyha770c72_0.conda            25kB\n",
      "  importlib_resources-5.12.0-pyhd8ed1ab_0.conda          31kB\n",
      "  intel-openmp-2022.1.0-h9e868ea_3769.conda               5MB\n",
      "  jinja2-3.1.2-pyhd8ed1ab_1.tar.bz2                     101kB\n",
      "  jpeg-9e-h0b41bf4_3.conda                              240kB\n",
      "  lame-3.100-h166bdaf_1003.tar.bz2                      508kB\n",
      "  lcms2-2.15-hfd0df8a_0.conda                           241kB\n",
      "  ld_impl_linux-64-2.40-h41732ed_0.conda                705kB\n",
      "  lerc-4.0.0-h27087fc_0.tar.bz2                         282kB\n",
      "  libblas-3.9.0-16_linux64_mkl.tar.bz2                   13kB\n",
      "  libcblas-3.9.0-16_linux64_mkl.tar.bz2                  13kB\n",
      "  libcublas-11.11.3.6-0.tar.bz2                         382MB\n",
      "  libcufft-10.9.0.58-0.tar.bz2                          150MB\n",
      "  libcufile-1.6.0.25-0.tar.bz2                          782kB\n",
      "  libcurand-10.3.2.56-0.tar.bz2                          54MB\n",
      "  libcusolver-11.4.1.48-0.tar.bz2                       101MB\n",
      "  libcusparse-11.7.5.86-0.tar.bz2                       185MB\n",
      "  libdeflate-1.17-h0b41bf4_0.conda                       65kB\n",
      "  libffi-3.4.2-h7f98852_5.tar.bz2                        58kB\n",
      "  libgcc-ng-12.2.0-h65d4601_19.tar.bz2                  954kB\n",
      "  libgomp-12.2.0-h65d4601_19.tar.bz2                    466kB\n",
      "  libiconv-1.17-h166bdaf_0.tar.bz2                        1MB\n",
      "  liblapack-3.9.0-16_linux64_mkl.tar.bz2                 13kB\n",
      "  libnpp-11.8.0.86-0.tar.bz2                            155MB\n",
      "  libnsl-2.0.0-h7f98852_0.tar.bz2                        31kB\n",
      "  libnvjpeg-11.9.0.86-0.tar.bz2                           3MB\n",
      "  libpng-1.6.39-h753d276_0.conda                        283kB\n",
      "  libsqlite-3.40.0-h753d276_0.tar.bz2                   810kB\n",
      "  libstdcxx-ng-12.2.0-h46fd767_19.tar.bz2                 4MB\n",
      "  libtiff-4.5.0-h6adf6a1_2.conda                        407kB\n",
      "  libuuid-2.38.1-h0b41bf4_0.conda                        34kB\n",
      "  libwebp-base-1.3.0-h0b41bf4_0.conda                   357kB\n",
      "  libxcb-1.13-h7f98852_1004.tar.bz2                     400kB\n",
      "  libzlib-1.2.13-h166bdaf_4.tar.bz2                      66kB\n",
      "  locket-1.0.0-pyhd8ed1ab_0.tar.bz2                       8kB\n",
      "  lz4-4.3.2-py310h0cfdcf0_0.conda                        37kB\n",
      "  lz4-c-1.9.4-hcb278e6_0.conda                          143kB\n",
      "  mako-1.2.4-pyhd8ed1ab_0.tar.bz2                        63kB\n",
      "  markupsafe-2.1.2-py310h1fa729e_0.conda                 23kB\n",
      "  mkl-2022.1.0-hc2b9512_224.conda                       136MB\n",
      "  mpc-1.3.1-hfe3b2da_0.conda                            116kB\n",
      "  mpfr-4.2.0-hb012696_0.conda                           631kB\n",
      "  mpmath-1.3.0-pyhd8ed1ab_0.conda                       438kB\n",
      "  msgpack-python-1.0.5-py310hdf3cbec_0.conda             85kB\n",
      "  ncurses-6.3-h27087fc_1.tar.bz2                          1MB\n",
      "  nettle-3.6-he412f7d_0.tar.bz2                           7MB\n",
      "  networkx-3.1-pyhd8ed1ab_0.conda                         1MB\n",
      "  numpy-1.24.2-py310h8deb116_0.conda                      7MB\n",
      "  openh264-2.1.1-h780b84a_0.tar.bz2                       2MB\n",
      "  openjpeg-2.5.0-hfec8fc6_2.conda                       352kB\n",
      "  openssl-3.1.0-h0b41bf4_0.conda                          3MB\n",
      "  optuna-3.1.0-pyhd8ed1ab_0.conda                       218kB\n",
      "  packaging-23.1-pyhd8ed1ab_0.conda                      46kB\n",
      "  pandas-2.0.0-py310h9b08913_0.conda                     12MB\n",
      "  partd-1.4.0-pyhd8ed1ab_0.conda                         20kB\n",
      "  pillow-9.4.0-py310h023d228_1.conda                     46MB\n",
      "  pip-23.1-pyhd8ed1ab_0.conda                             1MB\n",
      "  psutil-5.9.4-py310h5764c6d_0.tar.bz2                  361kB\n",
      "  pthread-stubs-0.4-h36c2ea0_1001.tar.bz2                 6kB\n",
      "  pycparser-2.21-pyhd8ed1ab_0.tar.bz2                   103kB\n",
      "  pynvml-11.4.1-pyhd8ed1ab_0.tar.bz2                     41kB\n",
      "  pyopenssl-23.1.1-pyhd8ed1ab_0.conda                   128kB\n",
      "  pysocks-1.7.1-pyha2e5f31_6.tar.bz2                     19kB\n",
      "  python-3.10.10-he550d4f_0_cpython.conda                26MB\n",
      "  python-dateutil-2.8.2-pyhd8ed1ab_0.tar.bz2            246kB\n",
      "  python-tzdata-2023.3-pyhd8ed1ab_0.conda               143kB\n",
      "  python_abi-3.10-3_cp310.conda                           6kB\n",
      "  pytorch-2.0.0-py3.10_cuda11.8_cudnn8.7.0_0.tar.bz2      2GB\n",
      "  pytorch-cuda-11.8-h7e8668a_3.tar.bz2                    7kB\n",
      "  pytorch-mutex-1.0-cuda.tar.bz2                          3kB\n",
      "  pytz-2023.3-pyhd8ed1ab_0.conda                        187kB\n",
      "  pyyaml-6.0-py310h5764c6d_5.tar.bz2                    176kB\n",
      "  readline-8.2-h8228510_1.conda                         281kB\n",
      "  requests-2.28.2-pyhd8ed1ab_1.conda                     57kB\n",
      "  setuptools-67.6.1-pyhd8ed1ab_0.conda                  580kB\n",
      "  six-1.16.0-pyh6c4a22f_0.tar.bz2                        14kB\n",
      "  sortedcontainers-2.4.0-pyhd8ed1ab_0.tar.bz2            26kB\n",
      "  sqlalchemy-2.0.9-py310h1fa729e_0.conda                  3MB\n",
      "  sympy-1.11.1-pypyh9d50eac_103.conda                     5MB\n",
      "  tblib-1.7.0-pyhd8ed1ab_0.tar.bz2                       15kB\n",
      "  tk-8.6.12-h27826a3_0.tar.bz2                            3MB\n",
      "  toolz-0.12.0-pyhd8ed1ab_0.tar.bz2                      49kB\n",
      "  torchtriton-2.0.0-py310.tar.bz2                        66MB\n",
      "  torchvision-0.15.0-py310_cu118.tar.bz2                  8MB\n",
      "  tornado-6.2-py310h5764c6d_1.tar.bz2                   678kB\n",
      "  tqdm-4.65.0-pyhd8ed1ab_1.conda                         88kB\n",
      "  typing-extensions-4.5.0-hd8ed1ab_0.conda               10kB\n",
      "  typing_extensions-4.5.0-pyha770c72_0.conda             31kB\n",
      "  tzdata-2023c-h71feb2d_0.conda                         118kB\n",
      "  urllib3-1.26.15-pyhd8ed1ab_0.conda                    113kB\n",
      "  wheel-0.40.0-pyhd8ed1ab_0.conda                        56kB\n",
      "  xorg-libxau-1.0.9-h7f98852_0.tar.bz2                   13kB\n",
      "  xorg-libxdmcp-1.1.3-h7f98852_0.tar.bz2                 19kB\n",
      "  xz-5.2.6-h166bdaf_0.tar.bz2                           418kB\n",
      "  yaml-0.2.5-h7f98852_2.tar.bz2                          89kB\n",
      "  zict-2.2.0-pyhd8ed1ab_0.tar.bz2                        20kB\n",
      "  zipp-3.15.0-pyhd8ed1ab_0.conda                         17kB\n",
      "  zlib-1.2.13-h166bdaf_4.tar.bz2                         94kB\n",
      "  zstd-1.5.2-h3eb15da_6.conda                           420kB\n",
      "  /home/mambauser/.mamba/pkgs\n",
      "───────────────────────────────────────────────────────────────\n",
      "  \n",
      "───────────────────────────────────────────────────────────────\n",
      "  Total size:                                             4GB\n",
      "Cleaning tarballs..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove tarballs: [Y/n]   Package folder                                 Size\n",
      "───────────────────────────────────────────────────────\n",
      "  /opt/coiled/rt/pkgs\n",
      "───────────────────────────────────────────────────────\n",
      "  _libgcc_mutex-0.1-conda_forge                   6kB\n",
      "  _openmp_mutex-4.5-2_gnu                       102kB\n",
      "  alembic-1.10.3-pyhd8ed1ab_0                   909kB\n",
      "  blas-1.0-mkl                                    3kB\n",
      "  bokeh-2.4.3-pyhd8ed1ab_3                       81MB\n",
      "  brotlipy-0.7.0-py310h5764c6d_1005             820kB\n",
      "  bzip2-1.0.8-h7f98852_4                          2MB\n",
      "  ca-certificates-2022.12.7-ha878542_0          288kB\n",
      "  certifi-2022.12.7-pyhd8ed1ab_0                301kB\n",
      "  cffi-1.15.1-py310h255011f_3                   873kB\n",
      "  charset-normalizer-3.1.0-pyhd8ed1ab_0         181kB\n",
      "  click-8.1.3-unix_pyhd8ed1ab_2                 370kB\n",
      "  cloudpickle-2.2.1-pyhd8ed1ab_0                 98kB\n",
      "  cmaes-0.9.1-pyhd8ed1ab_0                       81kB\n",
      "  colorama-0.4.6-pyhd8ed1ab_0                    98kB\n",
      "  colorlog-6.7.0-py310hff52083_1                 55kB\n",
      "  cryptography-40.0.2-py310h34c0648_0             8MB\n",
      "  cuda-cudart-11.8.89-0                         738kB\n",
      "  cuda-cupti-11.8.87-0                          105MB\n",
      "  cuda-libraries-11.8.0-0                         4kB\n",
      "  cuda-nvrtc-11.8.89-0                           62MB\n",
      "  cuda-nvtx-11.8.86-0                           428kB\n",
      "  cuda-runtime-11.8.0-0                           4kB\n",
      "  cudatoolkit-11.8.0-h37601d7_11                  2GB\n",
      "  cytoolz-0.12.0-py310h5764c6d_1                  1MB\n",
      "  dask-2023.2.1-pyhd8ed1ab_0                     18kB\n",
      "  dask-core-2023.2.1-pyhd8ed1ab_0                 5MB\n",
      "  distributed-2023.2.1-pyhd8ed1ab_0               3MB\n",
      "  ffmpeg-4.3-hf484d3e_0                          25MB\n",
      "  filelock-3.11.0-pyhd8ed1ab_0                   41kB\n",
      "  freetype-2.12.1-hca18f0e_1                      3MB\n",
      "  fsspec-2023.4.0-pyh1a96a4e_0                  525kB\n",
      "  gmp-6.2.1-h58526e2_0                            3MB\n",
      "  gmpy2-2.1.2-py310h3ec546c_1                   754kB\n",
      "  gnutls-3.6.13-h85f3911_1                        9MB\n",
      "  greenlet-2.0.2-py310heca2aa9_0                793kB\n",
      "  heapdict-1.0.1-py_0                            19kB\n",
      "  idna-3.4-pyhd8ed1ab_0                         301kB\n",
      "  importlib-metadata-6.4.1-pyha770c72_0          92kB\n",
      "  importlib_resources-5.12.0-pyhd8ed1ab_0       131kB\n",
      "  intel-openmp-2022.1.0-h9e868ea_3769            33MB\n",
      "  jinja2-3.1.2-pyhd8ed1ab_1                     516kB\n",
      "  jpeg-9e-h0b41bf4_3                              1MB\n",
      "  lame-3.100-h166bdaf_1003                        2MB\n",
      "  lcms2-2.15-hfd0df8a_0                         822kB\n",
      "  ld_impl_linux-64-2.40-h41732ed_0                3MB\n",
      "  lerc-4.0.0-h27087fc_0                         884kB\n",
      "  libblas-3.9.0-16_linux64_mkl                   49kB\n",
      "  libcblas-3.9.0-16_linux64_mkl                  48kB\n",
      "  libcublas-11.11.3.6-0                         670MB\n",
      "  libcufft-10.9.0.58-0                          281MB\n",
      "  libcufile-1.6.0.25-0                            2MB\n",
      "  libcurand-10.3.2.56-0                          97MB\n",
      "  libcusolver-11.4.1.48-0                       487MB\n",
      "  libcusparse-11.7.5.86-0                       280MB\n",
      "  libdeflate-1.17-h0b41bf4_0                    190kB\n",
      "  libffi-3.4.2-h7f98852_5                       220kB\n",
      "  libgcc-ng-12.2.0-h65d4601_19                    3MB\n",
      "  libgomp-12.2.0-h65d4601_19                      1MB\n",
      "  libiconv-1.17-h166bdaf_0                        3MB\n",
      "  liblapack-3.9.0-16_linux64_mkl                 48kB\n",
      "  libnpp-11.8.0.86-0                            254MB\n",
      "  libnsl-2.0.0-h7f98852_0                       110kB\n",
      "  libnvjpeg-11.9.0.86-0                           6MB\n",
      "  libpng-1.6.39-h753d276_0                        1MB\n",
      "  libsqlite-3.40.0-h753d276_0                     2MB\n",
      "  libstdcxx-ng-12.2.0-h46fd767_19                12MB\n",
      "  libtiff-4.5.0-h6adf6a1_2                        1MB\n",
      "  libuuid-2.38.1-h0b41bf4_0                     128kB\n",
      "  libwebp-base-1.3.0-h0b41bf4_0                   1MB\n",
      "  libxcb-1.13-h7f98852_1004                       4MB\n",
      "  libzlib-1.2.13-h166bdaf_4                     132kB\n",
      "  locket-1.0.0-pyhd8ed1ab_0                      24kB\n",
      "  lz4-4.3.2-py310h0cfdcf0_0                     168kB\n",
      "  lz4-c-1.9.4-hcb278e6_0                        521kB\n",
      "  mako-1.2.4-pyhd8ed1ab_0                       301kB\n",
      "  markupsafe-2.1.2-py310h1fa729e_0               74kB\n",
      "  mkl-2022.1.0-hc2b9512_224                     799MB\n",
      "  mpc-1.3.1-hfe3b2da_0                            2MB\n",
      "  mpfr-4.2.0-hb012696_0                           6MB\n",
      "  mpmath-1.3.0-pyhd8ed1ab_0                       2MB\n",
      "  msgpack-python-1.0.5-py310hdf3cbec_0          283kB\n",
      "  ncurses-6.3-h27087fc_1                          5MB\n",
      "  nettle-3.6-he412f7d_0                          21MB\n",
      "  networkx-3.1-pyhd8ed1ab_0                       8MB\n",
      "  numpy-1.24.2-py310h8deb116_0                   31MB\n",
      "  openh264-2.1.1-h780b84a_0                       5MB\n",
      "  openjpeg-2.5.0-hfec8fc6_2                       2MB\n",
      "  openssl-3.1.0-h0b41bf4_0                       10MB\n",
      "  optuna-3.1.0-pyhd8ed1ab_0                       1MB\n",
      "  packaging-23.1-pyhd8ed1ab_0                   175kB\n",
      "  pandas-2.0.0-py310h9b08913_0                   58MB\n",
      "  partd-1.4.0-pyhd8ed1ab_0                       69kB\n",
      "  pillow-9.4.0-py310h023d228_1                   74MB\n",
      "  pip-23.1-pyhd8ed1ab_0                           7MB\n",
      "  psutil-5.9.4-py310h5764c6d_0                    2MB\n",
      "  pthread-stubs-0.4-h36c2ea0_1001                14kB\n",
      "  pycparser-2.21-pyhd8ed1ab_0                   686kB\n",
      "  pynvml-11.4.1-pyhd8ed1ab_0                    300kB\n",
      "  pyopenssl-23.1.1-pyhd8ed1ab_0                 606kB\n",
      "  pysocks-1.7.1-pyha2e5f31_6                     67kB\n",
      "  python-3.10.10-he550d4f_0_cpython              79MB\n",
      "  python-dateutil-2.8.2-pyhd8ed1ab_0            482kB\n",
      "  python-tzdata-2023.3-pyhd8ed1ab_0             752kB\n",
      "  python_abi-3.10-3_cp310                        14kB\n",
      "  pytorch-2.0.0-py3.10_cuda11.8_cudnn8.7.0_0      3GB\n",
      "  pytorch-cuda-11.8-h7e8668a_3                   36kB\n",
      "  pytorch-mutex-1.0-cuda                          7kB\n",
      "  pytz-2023.3-pyhd8ed1ab_0                        1MB\n",
      "  pyyaml-6.0-py310h5764c6d_5                    654kB\n",
      "  readline-8.2-h8228510_1                         1MB\n",
      "  requests-2.28.2-pyhd8ed1ab_1                  228kB\n",
      "  setuptools-67.6.1-pyhd8ed1ab_0                  3MB\n",
      "  six-1.16.0-pyh6c4a22f_0                        51kB\n",
      "  sortedcontainers-2.4.0-pyhd8ed1ab_0           147kB\n",
      "  sqlalchemy-2.0.9-py310h1fa729e_0               14MB\n",
      "  sympy-1.11.1-pypyh9d50eac_103                  32MB\n",
      "  tblib-1.7.0-pyhd8ed1ab_0                       58kB\n",
      "  tk-8.6.12-h27826a3_0                           11MB\n",
      "  toolz-0.12.0-pyhd8ed1ab_0                     219kB\n",
      "  torchtriton-2.0.0-py310                       207MB\n",
      "  torchvision-0.15.0-py310_cu118                 20MB\n",
      "  tornado-6.2-py310h5764c6d_1                     3MB\n",
      "  tqdm-4.65.0-pyhd8ed1ab_1                      374kB\n",
      "  typing-extensions-4.5.0-hd8ed1ab_0             26kB\n",
      "  typing_extensions-4.5.0-pyha770c72_0          135kB\n",
      "  tzdata-2023c-h71feb2d_0                       649kB\n",
      "  urllib3-1.26.15-pyhd8ed1ab_0                  472kB\n",
      "  wheel-0.40.0-pyhd8ed1ab_0                     223kB\n",
      "  xorg-libxau-1.0.9-h7f98852_0                   39kB\n",
      "  xorg-libxdmcp-1.1.3-h7f98852_0                 55kB\n",
      "  xz-5.2.6-h166bdaf_0                             2MB\n",
      "  yaml-0.2.5-h7f98852_2                         390kB\n",
      "  zict-2.2.0-pyhd8ed1ab_0                        79kB\n",
      "  zipp-3.15.0-pyhd8ed1ab_0                       52kB\n",
      "  zlib-1.2.13-h166bdaf_4                        294kB\n",
      "  zstd-1.5.2-h3eb15da_6                           1MB\n",
      "  /home/mambauser/.mamba/pkgs\n",
      "───────────────────────────────────────────────────────\n",
      "  \n",
      "───────────────────────────────────────────────────────\n",
      "  Total size:                                     9GB\n",
      "Cleaning packages..\n",
      "warning  libmamba This does not check for packages installed using\n",
      "    symlinks back to the package cache.\n",
      "Remove unused packages: [Y/n] [2023-04-17 09:18:24,789][INFO    ][cloud-env.build] Conda environment created\n",
      "[2023-04-17 09:18:24,790][INFO    ][cloud-env.scan] Scanning /opt/coiled/env\n",
      "[2023-04-17 09:18:24,812][INFO    ][cloud-env.scan] Conda environment detected: /opt/coiled/env\n",
      "[2023-04-17 09:18:24,943][INFO    ][cloud-env.build] Calculating chunks\n",
      "[2023-04-17 09:18:25,357][INFO    ][cloud-env.build] Environment size is 11297 MB \n",
      "[2023-04-17 09:18:25,357][INFO    ][cloud-env.build] Will split into 81 chunks\n",
      "[2023-04-17 09:18:25,357][INFO    ][cloud-env.build] Requesting multipart upload URLs for 81 chunks\n",
      "[2023-04-17 09:18:25,496][INFO    ][cloud-env.build] Received upload URLS for 81 chunks\n",
      "[2023-04-17 09:18:25,496][INFO    ][cloud-env.build] Uploading 81 chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logs end, may be truncated, see https://cloud.coiled.io/software/alias/19741/build/11603?account=dask-engineering&tab=logs for full output ---\n",
      "Creating GPU cluster...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc33bdaea5934593a8e6b5b56b07a3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milesg/mambaforge/envs/coiled-benchmarks/lib/python3.10/site-packages/distributed/client.py:1381: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+-------------+----------+-----------+----------+\n",
      "| Package     | Client   | Scheduler | Workers  |\n",
      "+-------------+----------+-----------+----------+\n",
      "| dask        | 2023.3.2 | 2023.2.1  | 2023.2.1 |\n",
      "| distributed | 2023.3.2 | 2023.2.1  | 2023.2.1 |\n",
      "| numpy       | 1.23.5   | 1.24.2    | 1.24.2   |\n",
      "| pandas      | 1.5.3    | 2.0.0     | 2.0.0    |\n",
      "+-------------+----------+-----------+----------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "source": [
    "print('Creating software environment...')\n",
    "coiled.create_software_environment(\n",
    "     name=name,\n",
    "     conda={\n",
    "         \"channels\": [\"pytorch\", \"nvidia\", \"conda-forge\", \"defaults\"],\n",
    "         \"dependencies\": [\n",
    "             \"dask=2023.2\",\n",
    "             \"pytorch=2.0.0\",\n",
    "             \"pytorch-cuda=11.8\",\n",
    "             \"optuna=3.1.0\",\n",
    "             \"torchvision\",\n",
    "             \"cudatoolkit=11.8.0\",\n",
    "             \"pynvml=11.4.1\",\n",
    "             \"numpy\"\n",
    "         ],\n",
    "     },\n",
    "     gpu_enabled=True,\n",
    " )\n",
    "\n",
    "\n",
    "print('Creating GPU cluster...')\n",
    "cluster = coiled.Cluster(\n",
    "    name=name,\n",
    "    software=name,\n",
    "    package_sync=False,\n",
    "    n_workers=8,\n",
    "    worker_gpu=True,\n",
    "    worker_options={\"nthreads\": 1},\n",
    ")\n",
    "\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc93dd",
   "metadata": {},
   "source": [
    "### TODO: If using package_sync, it won't install pytorch with Cuda even if that's what you have locally, so one would need to re-install it on the workers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eb929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from distributed import PipInstall\n",
    "\n",
    "#plugin = PipInstall(['torch', 'torchvision', 'torchaudio'], pip_options=['--force-reinstall'])\n",
    "#client.register_worker_plugin(plugin)\n",
    "\n",
    "#workers = list(client.scheduler_info()['workers'].keys())\n",
    "#client.restart_workers(workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d03fb7",
   "metadata": {},
   "source": [
    "### Perform hyperparameter tuning using Dask and Distributed on Coiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3122981",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_419484/3427342232.py:4: ExperimentalWarning: DaskStorage is experimental (supported from v3.1.0). The interface can change in the future.\n",
      "  study = optuna.create_study(direction='minimize', storage=DaskStorage(client=client))\n"
     ]
    }
   ],
   "source": [
    "# Set to your heart's desire, patience and cluster size. :)\n",
    "n_trials = 500\n",
    "\n",
    "study = optuna.create_study(direction='minimize', storage=DaskStorage(client=client))\n",
    "jobs = [\n",
    "    client.submit(study.optimize, objective, n_trials=1, pure=False)\n",
    "    for _ in range(n_trials)\n",
    "]\n",
    "_ = wait(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77538d36",
   "metadata": {},
   "source": [
    "### Analyze the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0e6fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  500\n",
      "  Number of pruned trials:  446\n",
      "  Number of complete trials:  54\n",
      "Best trial:\n",
      "  Value:  0.044867247343063354\n",
      "  Params: \n",
      "    generator_activation: 0\n",
      "    descriminator_activation: 0\n",
      "    descriminator_leaky_relu_slope: 0\n"
     ]
    }
   ],
   "source": [
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d5b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
